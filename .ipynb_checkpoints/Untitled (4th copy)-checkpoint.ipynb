{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling imbalanced datasets in machine learning\n",
    "\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "import random\n",
    "from sklearn import cluster\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "\n",
    "creditData=np.loadtxt('creditcard.csv',dtype=np.str,delimiter=',',skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(creditData.shape)\n",
    "\n",
    "#stripping \"\" from output variable\n",
    "creditData[:,creditData.shape[1]-1]=np.core.defchararray.strip(creditData[:,creditData.shape[1]-1], chars='\"')\n",
    "#type conversion\n",
    "creditData=creditData.astype(np.float)\n",
    "print(creditData.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "#1. Data Level Approach\n",
    "fraudRate=(np.count_nonzero(creditData[:,creditData.shape[1]-1])/creditData.shape[0])\n",
    "print(fraudRate)#ratio of non fraud to fraud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting between train and test set\n",
    "xTrain, xTest, yTrain, yTest=sklearn.model_selection.train_test_split(creditData[:,:creditData.shape[1]-1],creditData[:,creditData.shape[1]-1],test_size=0.20)\n",
    "\n",
    "#test contains test input and output both\n",
    "test=pd.DataFrame(xTest)\n",
    "test[test.shape[1]]=yTest\n",
    "testF=test[test[test.shape[1]-1]==1]#test data for fraud examples\n",
    "testNf=test[test[test.shape[1]-1]==0]#test data for non fraud examples\n",
    "\n",
    "\n",
    "train=pd.DataFrame(xTrain)\n",
    "train[train.shape[1]]=yTrain\n",
    "trainF=train[train[train.shape[1]-1]==1]#train data for fraud examples\n",
    "trainNf=train[train[train.shape[1]-1]==0]#train data for non fraud examples\n",
    "\n",
    "#reducing the size of data\n",
    "train=pd.DataFrame()\n",
    "xTrain=pd.DataFrame()\n",
    "yTrain=pd.DataFrame()\n",
    "for i in range(30000):\n",
    "    r=np.random.randint(0,trainNf.shape[0])\n",
    "    train=train.append(trainNf.iloc[r,:])  \n",
    "for i in range(30):\n",
    "    r=np.random.randint(0,trainF.shape[0])\n",
    "    train=train.append(trainF.iloc[r,:])\n",
    "\n",
    "xTrain=xTrain.append(train.loc[:,:train.shape[1]-2])\n",
    "yTrain[train.shape[1]-1]=train.loc[:,train.shape[1]-1]\n",
    "\n",
    "trainF=train[train[train.shape[1]-1]==1]\n",
    "trainNf=train[train[train.shape[1]-1]==0]\n",
    "\n",
    "testN=pd.DataFrame()\n",
    "for i in range(testF.shape[0]):\n",
    "    r=np.random.randint(0,testNf.shape[0])\n",
    "    testN=testN.append(testNf.iloc[r,:])\n",
    "testNf=testN\n",
    "print(xTrain.shape,yTrain.shape,trainF.shape,trainNf.shape,testF.shape,testNf.shape)\n",
    "\n",
    "'''#tsne\n",
    "Xnew=TSNE(n_components=2).fit_transform(xTrain)\n",
    "#print(\"K means for t-SNE\")\n",
    "\n",
    "#kmeans = KMeans(n_clusters=2).fit(Xnew)\n",
    "#y=kmeans.predict(Xnew)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "#matplotlib.pyplot.scatter(Xnew[:,0], Xnew[:,1], c=y, cmap='tab10')\n",
    "colors = ['blue','red']\n",
    "matplotlib.pyplot.scatter(Xnew[:,0], Xnew[:,1], c=np.ravel(yTrain.astype(np.int)), cmap=matplotlib.colors.ListedColormap(colors))\n",
    "#plt.title('Clustering of points after running the kmeans algorithm on tSNE redued data')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xnew.shape,yTrain.shape)\n",
    "print(np.ravel(yTrain.astype(np.int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random undersampling\n",
    "train=pd.DataFrame()\n",
    "for i in range(np.count_nonzero(yTrain)):\n",
    "    r=np.random.randint(0,trainNf.shape[0])\n",
    "    train=train.append(trainNf.iloc[r,:])  \n",
    "train=train.append(trainF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prototype based classification on original data(bad classification with eucledian distance metric)\n",
    "\n",
    "clf=sklearn.neighbors.NearestCentroid().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prototype based classification on original data(classification with minkowski distance with p=-1)\n",
    "\n",
    "def dist(x,y):\n",
    "    x=abs(x-y)\n",
    "    x=x**(-0.1)\n",
    "    s=np.sum(x)\n",
    "    s=s**(-1/0.1)\n",
    "    return s\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes classifier\n",
    "\n",
    "clf=GaussianNB().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#naive bayes classification on random undersampled data\n",
    "clf=GaussianNB().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree classifier\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier().fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "\n",
    "#decision tree classification on random undersampled data\n",
    "clf=sklearn.tree.DecisionTreeClassifier().fit(train.loc[:,:train.shape[1]-2],train.loc[:,train.shape[1]-1])\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier(class_weight={1:10}).fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K- nearest neighbor\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#K nearest neighbor classification on random undersampled data\n",
    "clf=sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precision\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression on original data\n",
    "#class sklearn.linear_model.LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None)\n",
    "clf=linear_model.LogisticRegression().fit(xTrain,np.ravel(yTrain))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#logistic regression on random undersampled data\n",
    "clf=linear_model.LogisticRegression().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(TN,TP,FP)\n",
    "print(\"precision \",precision)#precision\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "clf=linear_model.LogisticRegression(class_weight={1:10}).fit(xTrain,np.ravel(yTrain))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM on original data\n",
    "clf=sklearn.svm.SVC(kernel='linear',cache_size=4096,max_iter=200,verbose=True).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#SVM on random undersampled data\n",
    "clf=sklearn.svm.SVC(kernel='linear',cache_size=4096,max_iter=200,verbose=True).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "clf=sklearn.svm.SVC(kernel='linear',class_weight={1:10},cache_size=4096,verbose=True).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Oversampling\n",
    "\n",
    "train=pd.DataFrame()\n",
    "for i in range(yTrain.shape[0]-2*np.count_nonzero(yTrain)):\n",
    "    r=np.random.randint(0,trainF.shape[0])\n",
    "    train=train.append(trainF.iloc[r,:])  \n",
    "train=train.append(trainNf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prototype based classification on original data(classification with minkowski distance)\n",
    "\n",
    "\n",
    "def dist(x,y):\n",
    "    x=abs(x-y)\n",
    "    x=x**(-0.1)\n",
    "    s=np.sum(x)\n",
    "    s=s**(-1/0.1)\n",
    "    return s\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes classifier\n",
    "\n",
    "clf=GaussianNB().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#naive bayes classification on random undersampled data\n",
    "clf=GaussianNB().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree classifier\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier().fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#decision tree classification on random undersampled data\n",
    "clf=sklearn.tree.DecisionTreeClassifier().fit(train.loc[:,:train.shape[1]-2],train.loc[:,train.shape[1]-1])\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K- nearest neighbor\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#K nearest neighbor classification on random undersampled data\n",
    "clf=sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression on original data\n",
    "#class sklearn.linear_model.LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None)\n",
    "clf=linear_model.LogisticRegression().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#logistic regression on random undersampled data\n",
    "clf=linear_model.LogisticRegression().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM on original data\n",
    "clf=sklearn.svm.SVC(kernel='linear',cache_size=4096,max_iter=200,verbose=True).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "               \n",
    "#SVM on random undersampled data\n",
    "clf=sklearn.svm.SVC(kernel='linear',cache_size=4096,max_iter=200,verbose=True).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k means on non fraud data with number of centres=number of fraud data\n",
    "clf=cluster.KMeans(n_clusters=trainF.shape[0]).fit(trainNf.loc[:,:trainNf.shape[1]-2])\n",
    "train=pd.DataFrame(clf.cluster_centers_)\n",
    "train[train.shape[1]-1]=np.zeros(train.shape[0])\n",
    "train=train.append(trainF)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prototype based classification on original data(classification with minkowski distance)\n",
    "\n",
    "\n",
    "def dist(x,y):\n",
    "    x=abs(x-y)\n",
    "    x=x**(-0.1)\n",
    "    s=np.sum(x)\n",
    "    s=s**(-1/0.1)\n",
    "    return s\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes classifier\n",
    "\n",
    "clf=GaussianNB().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#naive bayes classification on random undersampled data\n",
    "clf=GaussianNB().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree classifier\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier().fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#decision tree classification on random undersampled data\n",
    "clf=sklearn.tree.DecisionTreeClassifier().fit(train.loc[:,:train.shape[1]-2],train.loc[:,train.shape[1]-1])\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K- nearest neighbor\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#K nearest neighbor classification on random undersampled data\n",
    "clf=sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression on original data\n",
    "#class sklearn.linear_model.LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None)\n",
    "clf=linear_model.LogisticRegression().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#logistic regression on random undersampled data\n",
    "clf=linear_model.LogisticRegression().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM on original data\n",
    "clf=sklearn.svm.SVC(kernel='linear',cache_size=4096,max_iter=200,verbose=True).fit(xTrain,np.ravel(yTrain))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#SVM on random undersampled data\n",
    "clf=sklearn.svm.SVC(kernel='linear',cache_size=4096,max_iter=200,verbose=True).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster based oversampling\n",
    "dataCluster=pd.DataFrame()\n",
    "dataCluster=dataCluster.append(trainNf)\n",
    "#making clusters\n",
    "clf1=cluster.KMeans(n_clusters=20).fit(trainNf.loc[:,:trainNf.shape[1]-2])\n",
    "clusterTotal=pd.DataFrame(clf1.predict(trainNf.loc[:,:trainNf.shape[1]-2]))\n",
    "dataCluster[31]=np.array(clusterTotal)\n",
    "clusterTotal1=clusterTotal.groupby([0]).size()\n",
    "clusterMax1=clusterTotal1.max()\n",
    "\n",
    "clf2=cluster.KMeans(n_clusters=2).fit(trainF.loc[:,:trainF.shape[1]-2])\n",
    "clusterTotal=pd.DataFrame(clf2.predict(trainF.loc[:,:trainF.shape[1]-2]))\n",
    "clusterTotal2=clusterTotal.groupby([0]).size()\n",
    "clusterMax2=20*clusterMax1//2\n",
    "\n",
    "#oversampling data of each cluster\n",
    "\n",
    "dataCluster=dataCluster.sort_values(by=trainNf.shape[1]-1)\n",
    "train=pd.DataFrame()\n",
    "train=train.append(trainNf)\n",
    "currind=0\n",
    "for i in range(20):\n",
    "    for j in (clusterMax1-clusterTotal1):\n",
    "        r=np.random.randint(0,clusterTotal1[i])\n",
    "        train=train.append(dataCluster.iloc[r+currind,:31])\n",
    "    currind=currind+clusterTotal1[i]\n",
    "#print(train.head)\n",
    "\n",
    "dataCluster=pd.DataFrame(trainF)\n",
    "dataCluster=dataCluster.sort_values(by=trainF.shape[1]-1)\n",
    "train=train.append(trainF)\n",
    "currind=0\n",
    "for i in range(2):\n",
    "    for j in range(clusterMax2):\n",
    "        r=np.random.randint(0,clusterTotal2[i])\n",
    "        train=train.append(dataCluster.iloc[r+currind,:31])\n",
    "    currind=currind+clusterTotal2[i]\n",
    "print(train.groupby([train.shape[1]-1]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prototype based classification on original data(classification with minkowski distance)\n",
    "\n",
    "\n",
    "def dist(x,y):\n",
    "    x=abs(x-y)\n",
    "    x=x**(-0.1)\n",
    "    s=np.sum(x)\n",
    "    s=s**(-1/0.1)\n",
    "    return s\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes classifier\n",
    "\n",
    "clf=GaussianNB().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#naive bayes classification on random undersampled data\n",
    "clf=GaussianNB().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree classifier\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier().fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#decision tree classification on random undersampled data\n",
    "clf=sklearn.tree.DecisionTreeClassifier().fit(train.loc[:,:train.shape[1]-2],train.loc[:,train.shape[1]-1])\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K- nearest neighbor\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "\n",
    "#K nearest neighbor classification on random undersampled data\n",
    "clf=sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression on original data\n",
    "#class sklearn.linear_model.LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None) \n",
    "clf=linear_model.LogisticRegression().fit(xTrain,np.ravel(yTrain))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#logistic regression on random undersampled data \n",
    "clf=linear_model.LogisticRegression().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]) )\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "#SVM on original data\n",
    "clf=sklearn.svm.SVC(kernel='linear',cache_size=4096,max_iter=200,verbose=True).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#SVM on random undersampled data\n",
    "clf=sklearn.svm.SVC(kernel='linear',cache_size=4096,max_iter=200,verbose=True).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote\n",
    "train=pd.DataFrame(trainF)\n",
    "print(train.shape)\n",
    "#print(trainF.iloc[0,:trainF.shape[1]-2])\n",
    "for i in range(yTrain.shape[0]-2*np.count_nonzero(yTrain)):\n",
    "    j=np.random.randint(0,trainF.shape[0])\n",
    "    neigh=sklearn.neighbors.KNeighborsClassifier(n_neighbors=1).fit(trainF.loc[:,:trainF.shape[1]-2],trainF.loc[:,trainF.shape[1]-1])\n",
    "    neighbour=neigh.kneighbors(np.reshape(np.array(trainF.iloc[j,:trainF.shape[1]-1]),(1,-1)), 2, False)\n",
    "    p=np.random.random()\n",
    "    newPoint=(trainF.iloc[j,:trainF.shape[1]-1])+p*(trainF.iloc[neighbour[0][1],:trainF.shape[1]-1]-trainF.iloc[j,:trainF.shape[1]-1])\n",
    "    newPoint=newPoint.append(pd.Series(1))\n",
    "    newPoint=newPoint.reset_index(drop=True)\n",
    "    train=train.append(newPoint,ignore_index=True)\n",
    "print(train.shape)\n",
    "train=train.append(trainNf)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prototype based classification on original data(classification with minkowski distance)\n",
    "\n",
    "\n",
    "def dist(x,y):\n",
    "    x=abs(x-y)\n",
    "    x=x**(-0.1)\n",
    "    s=np.sum(x)\n",
    "    s=s**(-1/0.1)\n",
    "    return s\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive bayes classifier\n",
    "\n",
    "clf=GaussianNB().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#naive bayes classification on random undersampled data\n",
    "clf=GaussianNB().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree classifier\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier().fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#decision tree classification on random undersampled data\n",
    "clf=sklearn.tree.DecisionTreeClassifier().fit(train.loc[:,:train.shape[1]-2],train.loc[:,train.shape[1]-1])\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K- nearest neighbor\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#K nearest neighbor classification on random undersampled data\n",
    "clf=sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression on original data\n",
    "#class sklearn.linear_model.LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None)\n",
    "clf=linear_model.LogisticRegression().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#logistic regression on random undersampled data\n",
    "clf=linear_model.LogisticRegression().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM on original data\n",
    "clf=sklearn.svm.SVC(kernel='linear',cache_size=4096,max_iter=200,verbose=True).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#SVM on random undersampled data\n",
    "clf=sklearn.svm.SVC(kernel='linear',cache_size=4096,max_iter=200,verbose=True).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
