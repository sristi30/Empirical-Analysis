{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from sklearn import mixture\n",
    "from sklearn import cluster\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data. Split data as test and train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ebd93a1f6f21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreditData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'creditcard.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreditData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcreditData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefchararray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreditData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcreditData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreditData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0mnshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "creditData = np.loadtxt('creditcard.csv', dtype = np.str, delimiter = ',', skiprows = 1)\n",
    "print(creditData.shape)\n",
    "creditData[:,30] = np.core.defchararray.strip(creditData[:,30], chars = '\"')\n",
    "creditData = creditData.astype(np.float)\n",
    "\n",
    "fraud_bool, counts = np.unique(creditData[:, 30], return_counts = True)\n",
    "print(\"Fraudulent transaction percentage: {}%\".format(counts[1] / (counts[0] + counts[1]) * 100))\n",
    "\n",
    "#splitting between train and test set\n",
    "xTrain, xTest, yTrain, yTest=sklearn.model_selection.train_test_split(creditData[:,:creditData.shape[1]-1],creditData[:,creditData.shape[1]-1],test_size=0.20)\n",
    "\n",
    "#test contains test input and output both\n",
    "test=pd.DataFrame(xTest)\n",
    "test[test.shape[1]]=yTest\n",
    "testF=test[test[test.shape[1]-1]==1]#test data for fraud examples\n",
    "testNf=test[test[test.shape[1]-1]==0]#test data for non fraud examples\n",
    "\n",
    "\n",
    "train=pd.DataFrame(xTrain)\n",
    "train[train.shape[1]]=yTrain\n",
    "trainF=train[train[train.shape[1]-1]==1]#train data for fraud examples\n",
    "trainNf=train[train[train.shape[1]-1]==0]#train data for non fraud examples\n",
    "\n",
    "#reducing the size of data\n",
    "train=pd.DataFrame()\n",
    "xTrain=pd.DataFrame()\n",
    "yTrain=pd.DataFrame()\n",
    "for i in range(30000):\n",
    "    r=np.random.randint(0,trainNf.shape[0])\n",
    "    train=train.append(trainNf.iloc[r,:])  \n",
    "for i in range(300):\n",
    "    r=np.random.randint(0,trainF.shape[0])\n",
    "    train=train.append(trainF.iloc[r,:])\n",
    "\n",
    "xTrain=xTrain.append(train.loc[:,:train.shape[1]-2])\n",
    "yTrain[train.shape[1]-1]=train.loc[:,train.shape[1]-1]\n",
    "\n",
    "trainF=train[train[train.shape[1]-1]==1]\n",
    "trainNf=train[train[train.shape[1]-1]==0]\n",
    "\n",
    "testN=pd.DataFrame()\n",
    "for i in range(testF.shape[0]):\n",
    "    r=np.random.randint(0,testNf.shape[0])\n",
    "    testN=testN.append(testNf.iloc[r,:])\n",
    "testNf=testN\n",
    "print(xTrain.shape,yTrain.shape,trainF.shape,trainNf.shape,testF.shape,testNf.shape)\n",
    "\n",
    "trainX=xTrain\n",
    "trainY=yTrain\n",
    "testY=yTest\n",
    "trainY=yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creditDataDF = pd.read_csv('creditcard.csv')\n",
    "# plt.figure(figsize = [7,7])\n",
    "# plt.matshow(creditDataDF.corr(), fignum = 1)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# creditDataDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "of individual decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5% of data for each model\n",
    "bagModel = BaggingClassifier(base_estimator = None, n_estimators = 25, max_samples = 14240, \n",
    "                    bootstrap = True).fit(trainX, trainY)\n",
    "predictedY = bagModel.predict(testX)\n",
    "\n",
    "confustion_matrix = confusion_matrix(testY, predictedY)\n",
    "print(confustion_matrix)\n",
    "print(\"Accuracy of fradulent transaction detection {}\"\n",
    "      .format(confustion_matrix[1][1] / (confustion_matrix[1][0] + confustion_matrix[1][1])))\n",
    "print(\"Accuracy of legitimate transaction detection {}\"\n",
    "      .format(confustion_matrix[0][0] / (confustion_matrix[0][0] + confustion_matrix[0][1])))\n",
    "print(\"Precision: {}\".format(confustion_matrix[1][1] / (confustion_matrix[1][1] + confustion_matrix[0][1])))\n",
    "print(\"Recall: {}\".format(confustion_matrix[1][1] / (confustion_matrix[1][1] + confustion_matrix[1][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcModel = RandomForestClassifier().fit(trainX, trainY)\n",
    "predictedY = rfcModel.predict(testX)\n",
    "\n",
    "confustion_matrix = confusion_matrix(testY, predictedY)\n",
    "print(confustion_matrix)\n",
    "print(\"Accuracy of fradulent transaction detection {}\"\n",
    "      .format(confustion_matrix[1][1] / (confustion_matrix[1][0] + confustion_matrix[1][1])))\n",
    "print(\"Accuracy of legitimate transaction detection {}\"\n",
    "      .format(confustion_matrix[0][0] / (confustion_matrix[0][0] + confustion_matrix[0][1])))\n",
    "print(\"Precision: {}\".format(confustion_matrix[1][1] / (confustion_matrix[1][1] + confustion_matrix[0][1])))\n",
    "print(\"Recall: {}\".format(confustion_matrix[1][1] / (confustion_matrix[1][1] + confustion_matrix[1][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EasyEnsemble\n",
    "Ensemble of decision trees, each trained on an independently drawn sample from the legitimate transactions and the same training data of fradulent transactions (balanced training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = np.hstack((trainX, trainY.reshape(trainY.shape[0], 1)))\n",
    "legitimateTrans = trainData[np.where(trainY[:] == 0)][:, 0:31]\n",
    "fraudulentTrans = trainData[np.where(trainY[:] == 1)][:, 0:31]\n",
    "fraudX = fraudulentTrans[:,0:30]\n",
    "\n",
    "num_DT = 8\n",
    "\n",
    "running_prediction = np.zeros(testX.shape[0])\n",
    "for i in range(num_DT):\n",
    "    x = legitimateTrans[np.random.choice(legitimateTrans.shape[0], fraudulentTrans.shape[0]), :]\n",
    "    m = np.vstack((x, fraudulentTrans))\n",
    "    clf = tree.DecisionTreeClassifier().fit(m[:,0:30], m[:,30])\n",
    "    running_prediction = running_prediction + clf.predict(testX)\n",
    "    \n",
    "predictedY = (running_prediction / num_DT).astype(np.int)\n",
    "\n",
    "confustion_matrix = confusion_matrix(testY, predictedY)\n",
    "print(confustion_matrix)\n",
    "print(\"Accuracy of fradulent transaction detection {}\"\n",
    "      .format(confustion_matrix[1][1] / (confustion_matrix[1][0] + confustion_matrix[1][1])))\n",
    "print(\"Accuracy of legitimate transaction detection {}\"\n",
    "      .format(confustion_matrix[0][0] / (confustion_matrix[0][0] + confustion_matrix[0][1])))\n",
    "print(\"Precision: {}\".format(confustion_matrix[1][1] / (confustion_matrix[1][1] + confustion_matrix[0][1])))\n",
    "print(\"Recall: {}\".format(confustion_matrix[1][1] / (confustion_matrix[1][1] + confustion_matrix[1][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting (try XGBoost instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boostModel = GradientBoostingClassifier(learning_rate = 0.03).fit(trainX, trainY)\n",
    "predictedY = boostModel.predict(testX)\n",
    "\n",
    "confustion_matrix = confusion_matrix(testY, predictedY)\n",
    "print(confustion_matrix)\n",
    "print(\"Accuracy of fradulent transaction detection {}\"\n",
    "      .format(confustion_matrix[1][1] / (confustion_matrix[1][0] + confustion_matrix[1][1])))\n",
    "print(\"Accuracy of legitimate transaction detection {}\"\n",
    "      .format(confustion_matrix[0][0] / (confustion_matrix[0][0] + confustion_matrix[0][1])))\n",
    "print(\"Precision: {}\".format(confustion_matrix[1][1] / (confustion_matrix[1][1] + confustion_matrix[0][1])))\n",
    "print(\"Recall: {}\".format(confustion_matrix[1][1] / (confustion_matrix[1][1] + confustion_matrix[1][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Generative model of legitimate transactions?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
