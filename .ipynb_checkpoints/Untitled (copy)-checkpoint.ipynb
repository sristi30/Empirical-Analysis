{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling imbalanced datasets in machine learning\n",
    "\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "import random\n",
    "from sklearn import cluster\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "\n",
    "creditData=np.loadtxt('creditcard.csv',dtype=np.str,delimiter=',',skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(creditData.shape)\n",
    "\n",
    "#stripping \"\" from output variable\n",
    "creditData[:,creditData.shape[1]-1]=np.core.defchararray.strip(creditData[:,creditData.shape[1]-1], chars='\"')\n",
    "#type conversion\n",
    "creditData=creditData.astype(np.float)\n",
    "print(creditData.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "#1. Data Level Approach\n",
    "fraudRate=(np.count_nonzero(creditData[:,creditData.shape[1]-1])/creditData.shape[0])\n",
    "print(fraudRate)#ratio of non fraud to fraud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330, 30) (330, 1) (30, 31) (300, 31) (87, 31) (87, 31)\n"
     ]
    }
   ],
   "source": [
    "#splitting between train and test set\n",
    "xTrain, xTest, yTrain, yTest=sklearn.model_selection.train_test_split(creditData[:,:creditData.shape[1]-1],creditData[:,creditData.shape[1]-1],test_size=0.20)\n",
    "\n",
    "#test contains test input and output both\n",
    "test=pd.DataFrame(xTest)\n",
    "test[test.shape[1]]=yTest\n",
    "testF=test[test[test.shape[1]-1]==1]#test data for fraud examples\n",
    "testNf=test[test[test.shape[1]-1]==0]#test data for non fraud examples\n",
    "\n",
    "\n",
    "train=pd.DataFrame(xTrain)\n",
    "train[train.shape[1]]=yTrain\n",
    "trainF=train[train[train.shape[1]-1]==1]#train data for fraud examples\n",
    "trainNf=train[train[train.shape[1]-1]==0]#train data for non fraud examples\n",
    "\n",
    "#reducing the size of data\n",
    "train=pd.DataFrame()\n",
    "xTrain=pd.DataFrame()\n",
    "yTrain=pd.DataFrame()\n",
    "for i in range(300):\n",
    "    r=random.randint(0,trainNf.shape[0])\n",
    "    train=train.append(trainNf.iloc[r,:])  \n",
    "for i in range(30):\n",
    "    r=random.randint(0,trainF.shape[0])\n",
    "    train=train.append(trainF.iloc[r,:])\n",
    "\n",
    "xTrain=xTrain.append(train.loc[:,:train.shape[1]-2])\n",
    "yTrain[train.shape[1]-1]=train.loc[:,train.shape[1]-1]\n",
    "\n",
    "trainF=train[train[train.shape[1]-1]==1]\n",
    "trainNf=train[train[train.shape[1]-1]==0]\n",
    "\n",
    "testN=pd.DataFrame()\n",
    "for i in range(testF.shape[0]):\n",
    "    r=random.randint(0,testNf.shape[0])\n",
    "    testN=testN.append(testNf.iloc[r,:])\n",
    "testNf=testN\n",
    "\n",
    "print(xTrain.shape,yTrain.shape,trainF.shape,trainNf.shape,testF.shape,testNf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random undersampling\n",
    "train=pd.DataFrame()\n",
    "for i in range(np.count_nonzero(yTrain)):\n",
    "    r=np.random.randint(0,trainNf.shape[0])\n",
    "    train=train.append(trainNf.iloc[r,:])  \n",
    "train=train.append(trainF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45977011494252873\n",
      "0.5172413793103449\n",
      "0.45977011494252873\n",
      "0.6091954022988506\n"
     ]
    }
   ],
   "source": [
    "#prototype based classification on original data(bad classification with eucledian distance metric)\n",
    "\n",
    "clf=sklearn.neighbors.NearestCentroid().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "print(clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  1.0\n",
      "recall  0.7816091954022989\n",
      "precision  1.0\n",
      "F1 score  0.8774193548387098\n",
      "accuracy on non fraud samples  1.0\n",
      "recall  0.7701149425287356\n",
      "precision  1.0\n",
      "F1 score  0.8701298701298702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/nearest_centroid.py:140: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n"
     ]
    }
   ],
   "source": [
    "#prototype based classification on original data(classification with minkowski distance with p=-1)\n",
    "\n",
    "def dist(x,y):\n",
    "    x=abs(x-y)\n",
    "    x=x**(-0.1)\n",
    "    s=np.sum(x)\n",
    "    s=s**(-1/0.1)\n",
    "    return s\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "\n",
    "#Naive bayes classifier\n",
    "\n",
    "clf=GaussianNB().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "#naive bayes classification on random undersampled data\n",
    "clf=GaussianNB().fit(train.loc[:,:train.shape[1]-2],np.ravel(train.loc[:,train.shape[1]-1]))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:testNf.shape[1]-2],testNf.loc[:,testNf.shape[1]-1])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1])/(precision+(clf.score(testF.loc[:,:testF.shape[1]-2],testF.loc[:,testF.shape[1]-1]))))\n",
    "\n",
    "\n",
    "#Decision tree classifier\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier().fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "#decision tree classification on random undersampled data\n",
    "clf=sklearn.tree.DecisionTreeClassifier().fit(train.loc[:,:29],train.loc[:,30])\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier(class_weight={1:10}).fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "# K- nearest neighbor\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#K nearest neighbor classification on random undersampled data\n",
    "clf=sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precision\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "#logistic regression on original data\n",
    "#class sklearn.linear_model.LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None)\n",
    "clf=linear_model.LogisticRegression().fit(xTrain,np.ravel(yTrain))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#logistic regression on random undersampled data\n",
    "clf=linear_model.LogisticRegression().fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(TN,TP,FP)\n",
    "print(\"precision \",precision)#precision\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "clf=linear_model.LogisticRegression(class_weight={1:10}).fit(xTrain,np.ravel(yTrain))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#SVM on original data\n",
    "clf=sklearn.svm.SVC(kernel='linear').fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#SVM on random undersampled data\n",
    "clf=sklearn.svm.SVC(kernel='linear').fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "clf=sklearn.svm.SVC(kernel='linear',class_weight={1:10}).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "#Random Oversampling\n",
    "\n",
    "train=pd.DataFrame()\n",
    "for i in range(yTrain.shape[0]-2*np.count_nonzero(yTrain)):\n",
    "    r=np.random.randint(0,trainF.shape[0])\n",
    "    train=train.append(trainF.iloc[r,:])  \n",
    "train=train.append(trainNf)\n",
    "\n",
    "\n",
    "#prototype based classification on original data(classification with minkowski distance)\n",
    "\n",
    "\n",
    "def dist(x,y):\n",
    "    x=abs(x-y)\n",
    "    x=x**(-0.1)\n",
    "    s=np.sum(x)\n",
    "    s=s**(-1/0.1)\n",
    "    return s\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "#Naive bayes classifier\n",
    "\n",
    "clf=GaussianNB().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#naive bayes classification on random undersampled data\n",
    "clf=GaussianNB().fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "#Decision tree classifier\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier().fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#decision tree classification on random undersampled data\n",
    "clf=sklearn.tree.DecisionTreeClassifier().fit(train.loc[:,:29],train.loc[:,30])\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "# K- nearest neighbor\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#K nearest neighbor classification on random undersampled data\n",
    "clf=sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "#logistic regression on original data\n",
    "#class sklearn.linear_model.LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None)\n",
    "clf=linear_model.LogisticRegression().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#logistic regression on random undersampled data\n",
    "clf=linear_model.LogisticRegression().fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "\n",
    "#SVM on original data\n",
    "clf=sklearn.svm.SVC(kernel='linear').fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "               \n",
    "#SVM on random undersampled data\n",
    "clf=sklearn.svm.SVC(kernel='linear').fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "#k means on non fraud data with number of centres=number of fraud data\n",
    "clf=cluster.KMeans(n_clusters=trainF.shape[0]).fit(trainNf.loc[:,:29])\n",
    "train=pd.DataFrame(clf.cluster_centers_)\n",
    "train[30]=np.zeros(train.shape[0])\n",
    "train=train.append(trainF)\n",
    "print(train.shape)\n",
    "\n",
    "#prototype based classification on original data(classification with minkowski distance)\n",
    "\n",
    "\n",
    "def dist(x,y):\n",
    "    x=abs(x-y)\n",
    "    x=x**(-0.1)\n",
    "    s=np.sum(x)\n",
    "    s=s**(-1/0.1)\n",
    "    return s\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.6\n",
      "precision  0.9692307692307692\n",
      "F1 score  0.7411764705882353\n",
      "accuracy on non fraud samples  0.9619047619047619\n",
      "recall  0.7047619047619048\n",
      "precision  0.9487179487179487\n",
      "F1 score  0.8087431693989072\n"
     ]
    }
   ],
   "source": [
    "#Naive bayes classifier\n",
    "\n",
    "clf=GaussianNB().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#naive bayes classification on random undersampled data\n",
    "clf=GaussianNB().fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.7904761904761904\n",
      "precision  0.9764705882352941\n",
      "F1 score  0.8736842105263157\n",
      "accuracy on non fraud samples  0.8571428571428571\n",
      "recall  0.8952380952380953\n",
      "precision  0.8623853211009175\n",
      "F1 score  0.8785046728971964\n"
     ]
    }
   ],
   "source": [
    "#Decision tree classifier\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier().fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#decision tree classification on random undersampled data\n",
    "clf=sklearn.tree.DecisionTreeClassifier().fit(train.loc[:,:29],train.loc[:,30])\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in power\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9523809523809523\n",
      "recall  0.5904761904761905\n",
      "precision  0.9253731343283582\n",
      "F1 score  0.7209302325581395\n",
      "accuracy on non fraud samples  0.9428571428571428\n",
      "recall  0.819047619047619\n",
      "precision  0.9347826086956522\n",
      "F1 score  0.8730964467005077\n"
     ]
    }
   ],
   "source": [
    "# K- nearest neighbor\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#K nearest neighbor classification on random undersampled data\n",
    "clf=sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.7904761904761904\n",
      "precision  0.9764705882352941\n",
      "F1 score  0.8736842105263157\n",
      "accuracy on non fraud samples  0.9523809523809523\n",
      "recall  0.9047619047619048\n",
      "precision  0.95\n",
      "F1 score  0.9268292682926829\n"
     ]
    }
   ],
   "source": [
    "#logistic regression on original data\n",
    "#class sklearn.linear_model.LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None)\n",
    "clf=linear_model.LogisticRegression().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#logistic regression on random undersampled data\n",
    "clf=linear_model.LogisticRegression().fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.3619047619047619\n",
      "precision  0.95\n",
      "F1 score  0.5241379310344827\n",
      "accuracy on non fraud samples  0.9904761904761905\n",
      "recall  0.5333333333333333\n",
      "precision  0.9824561403508771\n",
      "F1 score  0.691358024691358\n"
     ]
    }
   ],
   "source": [
    "#SVM on original data\n",
    "clf=sklearn.svm.SVC(kernel='linear').fit(xTrain,np.ravel(yTrain))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#SVM on random undersampled data\n",
    "clf=sklearn.svm.SVC(kernel='linear').fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "0.0    700\n",
      "1.0    470\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#cluster based oversampling\n",
    "dataCluster=pd.DataFrame()\n",
    "dataCluster=dataCluster.append(trainNf)\n",
    "#making clusters\n",
    "clf1=cluster.KMeans(n_clusters=20).fit(trainNf.loc[:,:29])\n",
    "clusterTotal=pd.DataFrame(clf1.predict(trainNf.loc[:,:29]))\n",
    "dataCluster[31]=np.array(clusterTotal)\n",
    "clusterTotal1=clusterTotal.groupby([0]).size()\n",
    "clusterMax1=clusterTotal1.max()\n",
    "\n",
    "clf2=cluster.KMeans(n_clusters=2).fit(trainF.loc[:,:29])\n",
    "clusterTotal=pd.DataFrame(clf2.predict(trainF.loc[:,:29]))\n",
    "clusterTotal2=clusterTotal.groupby([0]).size()\n",
    "clusterMax2=20*clusterMax1//2\n",
    "\n",
    "#oversampling data of each cluster\n",
    "\n",
    "dataCluster=dataCluster.sort_values(by=30)\n",
    "train=pd.DataFrame()\n",
    "train=train.append(trainNf)\n",
    "currind=0\n",
    "for i in range(20):\n",
    "    for j in (clusterMax1-clusterTotal1):\n",
    "        r=np.random.randint(0,clusterTotal1[i])\n",
    "        train=train.append(dataCluster.iloc[r+currind,:31])\n",
    "    currind=currind+clusterTotal1[i]\n",
    "#print(train.head)\n",
    "\n",
    "dataCluster=pd.DataFrame(trainF)\n",
    "dataCluster=dataCluster.sort_values(by=30)\n",
    "train=train.append(trainF)\n",
    "currind=0\n",
    "for i in range(2):\n",
    "    for j in range(clusterMax2):\n",
    "        r=np.random.randint(0,clusterTotal2[i])\n",
    "        train=train.append(dataCluster.iloc[r+currind,:31])\n",
    "    currind=currind+clusterTotal2[i]\n",
    "print(train.groupby([30]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9904761904761905\n",
      "recall  0.6\n",
      "precision  0.984375\n",
      "F1 score  0.7455621301775147\n",
      "accuracy on non fraud samples  0.9904761904761905\n",
      "recall  0.5714285714285714\n",
      "precision  0.9836065573770492\n",
      "F1 score  0.7228915662650602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/nearest_centroid.py:140: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n"
     ]
    }
   ],
   "source": [
    "#prototype based classification on original data(classification with minkowski distance)\n",
    "\n",
    "\n",
    "def dist(x,y):\n",
    "    x=abs(x-y)\n",
    "    x=x**(-0.1)\n",
    "    s=np.sum(x)\n",
    "    s=s**(-1/0.1)\n",
    "    return s\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.6\n",
      "precision  0.9692307692307692\n",
      "F1 score  0.7411764705882353\n",
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.6571428571428571\n",
      "precision  0.971830985915493\n",
      "F1 score  0.7840909090909092\n"
     ]
    }
   ],
   "source": [
    "#Naive bayes classifier\n",
    "\n",
    "clf=GaussianNB().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#naive bayes classification on random undersampled data\n",
    "clf=GaussianNB().fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9714285714285714\n",
      "recall  0.8\n",
      "precision  0.9655172413793104\n",
      "F1 score  0.8750000000000001\n",
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.7714285714285715\n",
      "precision  0.9759036144578314\n",
      "F1 score  0.8617021276595745\n"
     ]
    }
   ],
   "source": [
    "#Decision tree classifier\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier().fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#decision tree classification on random undersampled data\n",
    "clf=sklearn.tree.DecisionTreeClassifier().fit(train.loc[:,:29],train.loc[:,30])\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in power\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9523809523809523\n",
      "recall  0.5904761904761905\n",
      "precision  0.9253731343283582\n",
      "F1 score  0.7209302325581395\n",
      "accuracy on non fraud samples  0.9428571428571428\n",
      "recall  0.7904761904761904\n",
      "precision  0.9325842696629213\n",
      "F1 score  0.8556701030927835\n"
     ]
    }
   ],
   "source": [
    "# K- nearest neighbor\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "\n",
    "#K nearest neighbor classification on random undersampled data\n",
    "clf=sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.7904761904761904\n",
      "precision  0.9764705882352941\n",
      "F1 score  0.8736842105263157\n",
      "accuracy on non fraud samples  0.9904761904761905\n",
      "recall  0.7619047619047619\n",
      "precision  0.9876543209876543\n",
      "F1 score  0.8602150537634409\n"
     ]
    }
   ],
   "source": [
    "#logistic regression on original data\n",
    "#class sklearn.linear_model.LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None) \n",
    "clf=linear_model.LogisticRegression().fit(xTrain,np.ravel(yTrain))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#logistic regression on random undersampled data \n",
    "clf=linear_model.LogisticRegression().fit(train.loc[:,:29],np.ravel(train.loc[:,30]) )\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.3619047619047619\n",
      "precision  0.95\n",
      "F1 score  0.5241379310344827\n",
      "accuracy on non fraud samples  0.9904761904761905\n",
      "recall  0.6857142857142857\n",
      "precision  0.9863013698630136\n",
      "F1 score  0.8089887640449438\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "#SVM on original data\n",
    "clf=sklearn.svm.SVC(kernel='linear').fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#SVM on random undersampled data\n",
    "clf=sklearn.svm.SVC(kernel='linear').fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 31)\n",
      "(300, 31)\n",
      "(600, 31)\n"
     ]
    }
   ],
   "source": [
    "#smote\n",
    "train=pd.DataFrame(trainF)\n",
    "print(train.shape)\n",
    "#print(trainF.iloc[0,:29])\n",
    "for i in range(yTrain.shape[0]-2*np.count_nonzero(yTrain)):\n",
    "    j=np.random.randint(0,trainF.shape[0])\n",
    "    neigh=sklearn.neighbors.KNeighborsClassifier(n_neighbors=1).fit(trainF.loc[:,:29],trainF.loc[:,30])\n",
    "    neighbour=neigh.kneighbors(np.reshape(np.array(trainF.iloc[j,:30]),(1,-1)), 2, False)\n",
    "    p=np.random.random()\n",
    "    newPoint=(trainF.iloc[j,:30])+p*(trainF.iloc[neighbour[0][1],:30]-trainF.iloc[j,:30])\n",
    "    newPoint=newPoint.append(pd.Series(1))\n",
    "    newPoint=newPoint.reset_index(drop=True)\n",
    "    train=train.append(newPoint,ignore_index=True)\n",
    "print(train.shape)\n",
    "train=train.append(trainNf)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9904761904761905\n",
      "recall  0.6\n",
      "precision  0.984375\n",
      "F1 score  0.7455621301775147\n",
      "accuracy on non fraud samples  0.9904761904761905\n",
      "recall  0.4666666666666667\n",
      "precision  0.98\n",
      "F1 score  0.632258064516129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/nearest_centroid.py:140: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n"
     ]
    }
   ],
   "source": [
    "#prototype based classification on original data(classification with minkowski distance)\n",
    "\n",
    "\n",
    "def dist(x,y):\n",
    "    x=abs(x-y)\n",
    "    x=x**(-0.1)\n",
    "    s=np.sum(x)\n",
    "    s=s**(-1/0.1)\n",
    "    return s\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#prototype based classification on random undersampled data\n",
    "clf=sklearn.neighbors.NearestCentroid(metric=dist).fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.6\n",
      "precision  0.9692307692307692\n",
      "F1 score  0.7411764705882353\n",
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.6571428571428571\n",
      "precision  0.971830985915493\n",
      "F1 score  0.7840909090909092\n"
     ]
    }
   ],
   "source": [
    "#Naive bayes classifier\n",
    "\n",
    "clf=GaussianNB().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#naive bayes classification on random undersampled data\n",
    "clf=GaussianNB().fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9714285714285714\n",
      "recall  0.7619047619047619\n",
      "precision  0.963855421686747\n",
      "F1 score  0.8510638297872339\n",
      "accuracy on non fraud samples  0.9714285714285714\n",
      "recall  0.8\n",
      "precision  0.9655172413793104\n",
      "F1 score  0.8750000000000001\n"
     ]
    }
   ],
   "source": [
    "#Decision tree classifier\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier().fit(xTrain,yTrain)\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#decision tree classification on random undersampled data\n",
    "clf=sklearn.tree.DecisionTreeClassifier().fit(train.loc[:,:29],train.loc[:,30])\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in power\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9523809523809523\n",
      "recall  0.5904761904761905\n",
      "precision  0.9253731343283582\n",
      "F1 score  0.7209302325581395\n",
      "accuracy on non fraud samples  0.9523809523809523\n",
      "recall  0.8\n",
      "precision  0.9438202247191011\n",
      "F1 score  0.8659793814432991\n"
     ]
    }
   ],
   "source": [
    "# K- nearest neighbor\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#K nearest neighbor classification on random undersampled data\n",
    "clf=sklearn.neighbors.KNeighborsClassifier(metric=dist).fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.7904761904761904\n",
      "precision  0.9764705882352941\n",
      "F1 score  0.8736842105263157\n",
      "accuracy on non fraud samples  0.9714285714285714\n",
      "recall  0.8476190476190476\n",
      "precision  0.967391304347826\n",
      "F1 score  0.9035532994923857\n"
     ]
    }
   ],
   "source": [
    "#logistic regression on original data\n",
    "#class sklearn.linear_model.LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None)\n",
    "clf=linear_model.LogisticRegression().fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#logistic regression on random undersampled data\n",
    "clf=linear_model.LogisticRegression().fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.3619047619047619\n",
      "precision  0.95\n",
      "F1 score  0.5241379310344827\n",
      "accuracy on non fraud samples  0.9809523809523809\n",
      "recall  0.7428571428571429\n",
      "precision  0.975\n",
      "F1 score  0.8432432432432432\n"
     ]
    }
   ],
   "source": [
    "#SVM on original data\n",
    "clf=sklearn.svm.SVC(kernel='linear').fit(xTrain,np.ravel(yTrain))\n",
    "\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n",
    "\n",
    "#SVM on random undersampled data\n",
    "clf=sklearn.svm.SVC(kernel='linear').fit(train.loc[:,:29],np.ravel(train.loc[:,30]))\n",
    "print(\"accuracy on non fraud samples \",clf.score(testNf.loc[:,:29],testNf.loc[:,30]))#accuracy on non fraud examples\n",
    "print(\"recall \", clf.score(testF.loc[:,:29],testF.loc[:,30]))#accuracy on fraud examples(recall)\n",
    "TP=clf.score(testF.loc[:,:29],testF.loc[:,30])*(testF.shape[0])\n",
    "TN=clf.score(testNf.loc[:,:29],testNf.loc[:,30])*(testNf.shape[0])\n",
    "FP=(testNf.shape[0])-TN\n",
    "precision=(TP)/(TP+FP)\n",
    "print(\"precision \",precision)#precisio\n",
    "print(\"F1 score \",2*precision*clf.score(testF.loc[:,:29],testF.loc[:,30])/(precision+(clf.score(testF.loc[:,:29],testF.loc[:,30]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
